{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "202439e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--mode MODE] [--filePath FILEPATH]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f C:\\Users\\US593\\AppData\\Roaming\\jupyter\\runtime\\kernel-c4beb675-b9a1-4883-8f9a-0470e72a37bc.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\US593\\AI\\04_CV\\01_CV\\OpenCV Tutorial\\Projects\\coldetenv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3534: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import argparse\n",
    "\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "\n",
    "\n",
    "def process_img(img, face_detection):\n",
    "\n",
    "    H, W, _ = img.shape\n",
    "\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    out = face_detection.process(img_rgb)\n",
    "\n",
    "    if out.detections is not None:\n",
    "        for detection in out.detections:\n",
    "            location_data = detection.location_data\n",
    "            bbox = location_data.relative_bounding_box\n",
    "\n",
    "            x1, y1, w, h = bbox.xmin, bbox.ymin, bbox.width, bbox.height\n",
    "\n",
    "            x1 = int(x1 * W)\n",
    "            y1 = int(y1 * H)\n",
    "            w = int(w * W)\n",
    "            h = int(h * H)\n",
    "\n",
    "            # print(x1, y1, w, h)\n",
    "\n",
    "            # blur faces\n",
    "            img[y1:y1 + h, x1:x1 + w, :] = cv2.blur(img[y1:y1 + h, x1:x1 + w, :], (30, 30))\n",
    "\n",
    "    return img\n",
    "\n",
    "\n",
    "args = argparse.ArgumentParser()\n",
    "\n",
    "args.add_argument(\"--mode\", default='webcam')\n",
    "args.add_argument(\"--filePath\", default=None)\n",
    "\n",
    "args = args.parse_args()\n",
    "\n",
    "\n",
    "output_dir = './output'\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# detect faces\n",
    "mp_face_detection = mp.solutions.face_detection\n",
    "\n",
    "with mp_face_detection.FaceDetection(model_selection=0, min_detection_confidence=0.5) as face_detection:\n",
    "\n",
    "    if args.mode in [\"image\"]:\n",
    "        # read image\n",
    "        img = cv2.imread(args.filePath)\n",
    "\n",
    "        img = process_img(img, face_detection)\n",
    "\n",
    "        # save image\n",
    "        cv2.imwrite(os.path.join(output_dir, 'output.png'), img)\n",
    "\n",
    "    elif args.mode in ['video']:\n",
    "\n",
    "        cap = cv2.VideoCapture(args.filePath)\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        output_video = cv2.VideoWriter(os.path.join(output_dir, 'output.mp4'),\n",
    "                                       cv2.VideoWriter_fourcc(*'MP4V'),\n",
    "                                       25,\n",
    "                                       (frame.shape[1], frame.shape[0]))\n",
    "\n",
    "        while ret:\n",
    "\n",
    "            frame = process_img(frame, face_detection)\n",
    "\n",
    "            output_video.write(frame)\n",
    "\n",
    "            ret, frame = cap.read()\n",
    "\n",
    "        cap.release()\n",
    "        output_video.release()\n",
    "\n",
    "    elif args.mode in ['webcam']:\n",
    "        cap = cv2.VideoCapture(2)\n",
    "\n",
    "        ret, frame = cap.read()\n",
    "        while ret:\n",
    "            frame = process_img(frame, face_detection)\n",
    "\n",
    "            cv2.imshow('frame', frame)\n",
    "            cv2.waitKey(25)\n",
    "\n",
    "            ret, frame = cap.read()\n",
    "\n",
    "        cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842f598f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8d24d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47270f54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc1dd19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d15dc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf564aa3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3fdfa5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc5b31ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import mediapipe as mp\n",
    "\n",
    "\n",
    "# read image\n",
    "original_img = cv2.imread(os.path.join('.','man.jpg'))\n",
    "img = cv2.resize(original_img,(700,500))\n",
    "H,W,_ = img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5975f36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_face_detection = mp.solutions.face_detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a832b74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "[label_id: 0\n",
      "score: 0.94820195\n",
      "location_data {\n",
      "  format: RELATIVE_BOUNDING_BOX\n",
      "  relative_bounding_box {\n",
      "    xmin: 0.3829603\n",
      "    ymin: 0.30052727\n",
      "    width: 0.2820085\n",
      "    height: 0.39479178\n",
      "  }\n",
      "  relative_keypoints {\n",
      "    x: 0.464697\n",
      "    y: 0.4066798\n",
      "  }\n",
      "  relative_keypoints {\n",
      "    x: 0.57992506\n",
      "    y: 0.41286886\n",
      "  }\n",
      "  relative_keypoints {\n",
      "    x: 0.51640916\n",
      "    y: 0.50659895\n",
      "  }\n",
      "  relative_keypoints {\n",
      "    x: 0.5149256\n",
      "    y: 0.58352274\n",
      "  }\n",
      "  relative_keypoints {\n",
      "    x: 0.4045102\n",
      "    y: 0.43804657\n",
      "  }\n",
      "  relative_keypoints {\n",
      "    x: 0.6466641\n",
      "    y: 0.454152\n",
      "  }\n",
      "}\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "with mp_face_detection.FaceDetection(min_detection_confidence = 0.5, model_selection = 0) as face_detection:\n",
    "    img_rgb = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "    out = face_detection.process(img_rgb)\n",
    "    print(type(out.detections))\n",
    "    print(out.detections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f82cbeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inside the above list there seems to be an object with attributes like label_id, score, and location_data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7eac499e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'mediapipe.framework.formats.detection_pb2.Detection'>\n",
      "<class 'mediapipe.framework.formats.location_data_pb2.LocationData'>\n",
      "<class 'mediapipe.framework.formats.location_data_pb2.RelativeBoundingBox'>\n",
      "<class 'float'>\n"
     ]
    }
   ],
   "source": [
    "print(type(out.detections[0]))\n",
    "print(type(out.detections[0].location_data))\n",
    "print(type(out.detections[0].location_data.relative_bounding_box))\n",
    "print(type(out.detections[0].location_data.relative_bounding_box.xmin))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8468e275",
   "metadata": {},
   "outputs": [],
   "source": [
    "if out.detections is not None:\n",
    "    for detection in out.detections: # for loop is basically here handling multiple detections if exists.\n",
    "        location_data = detection.location_data\n",
    "        bbox = location_data.relative_bounding_box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "083802dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xmin: 0.3829603\n",
      "ymin: 0.30052727\n",
      "width: 0.2820085\n",
      "height: 0.39479178\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(bbox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db2ed16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1,y1,w,h = bbox.xmin, bbox.ymin , bbox.width ,bbox.height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a23eb917",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = int(x1*W)\n",
    "y1 = int(y1*H)\n",
    "w = int(w*W)\n",
    "h = int(h*H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fbd32f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv2.rectangle(img,(x1,y1),(x1+w,y1+h),(0,255,0),10)\n",
    "# cv2.imshow('a',img)\n",
    "# cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b5b1324b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img[y1:y1+h,x1:x1+w] = cv2.blur(img[y1:y1+h,x1:x1+w],(20,20))\n",
    "cv2.imshow('b',img)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "324f824a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imwrite(os.path.join('.','blurred_img.jpg'),img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3684ef3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60fc8b44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca285e25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6706f6d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598017d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c496df6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa49881b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07a14fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985db629",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e62ddb3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learn ArgParse first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8668fa44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import argparse\n",
    "import os\n",
    "import mediapipe as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3bfd6d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('data'):\n",
    "    os.mkdir('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66ef7044",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(img,face_detection):\n",
    "    H,W,_ = img.shape\n",
    "    img_rgb = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "    out = face_detection.process(img_rgb)\n",
    "    if out.detections is not None:\n",
    "        for detection in out.detections: \n",
    "            location_data = detection.location_data\n",
    "            bbox = location_data.relative_bounding_box\n",
    "    x1,y1,w,h = bbox.xmin, bbox.ymin , bbox.width ,bbox.height\n",
    "    x1 = int(x1*W)\n",
    "    y1 = int(y1*H)\n",
    "    w = int(w*W)\n",
    "    h = int(h*H)\n",
    "    img[y1:y1+h,x1:x1+w] = cv2.blur(img[y1:y1+h,x1:x1+w],(20,20))\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1cd649e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# args = argparse.ArgumentParser()\n",
    "# args.add_argument(\"--mode\",default = 'image')\n",
    "# args.add_argument(\"--filePath\",default = './data/img.png')\n",
    "# args = args.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0439a020",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mp_face_detection = mp.solutions.face_detection\n",
    "# with mp_face_detection.FaceDetection(min_detection_confidence = 0.5, model_selection = 0) as face_detection:\n",
    "#     if args.mode in ['image']:\n",
    "#         img = cv2.imread(args.path)\n",
    "#         img = process_image(img,face_detection)\n",
    "#         cv2.imwrite(os.path.join('output.png'),img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766ddc9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3fedf0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9700983",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471148ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea11095b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17ac016",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3363b976",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28aa30ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1675e6ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5bc068f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f714d49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4714d623",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd5a5ee2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751a41af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f95ee588",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74938869",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c561bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b53173",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005881e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e3a31c42",
   "metadata": {},
   "source": [
    "## Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37167674",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import mediapipe as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3cfa9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(img,face_detection):\n",
    "    H,W,_ = img.shape\n",
    "    img_rgb = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "    out = face_detection.process(img_rgb)\n",
    "    \n",
    "    if out.detections is not None:\n",
    "        for detection in out.detections: \n",
    "            location_data = detection.location_data\n",
    "            bbox = location_data.relative_bounding_box   \n",
    "        x1,y1,w,h = bbox.xmin, bbox.ymin , bbox.width ,bbox.height\n",
    "        x1 = int(x1*W)\n",
    "        y1 = int(y1*H)\n",
    "        w = int(w*W)\n",
    "        h = int(h*H)\n",
    "        if x1 >= 0 and y1 >= 0 and x1 + w <= W and y1 + h <= H:\n",
    "            img[y1:y1+h,x1:x1+w] = cv2.blur(img[y1:y1+h,x1:x1+w],(20,20))         \n",
    "        return img   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00144632",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_face_detection = mp.solutions.face_detection\n",
    "with mp_face_detection.FaceDetection(min_detection_confidence = 0.5, model_selection = 0) as face_detection:\n",
    "    webcam = cv2.VideoCapture(0)\n",
    "    while True:\n",
    "        ret,frame = webcam.read()\n",
    "        frame_blured = process_image(frame,face_detection)\n",
    "        if frame_blured is not None:\n",
    "            cv2.imshow('webcam',frame_blured)\n",
    "            if cv2.waitKey(40) & 0xFF == ord('n'):\n",
    "                break\n",
    "        else : \n",
    "            cv2.imshow('webcam',frame)\n",
    "            if cv2.waitKey(40) & 0xFF == ord('n'):\n",
    "                break\n",
    "    webcam.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008c1717",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
